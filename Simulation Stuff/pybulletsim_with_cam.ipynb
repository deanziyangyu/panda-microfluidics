{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic pybullet simulation of iterative movement based on franka_test.py IK code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: roboticstoolbox-python in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: spatialmath-python in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (1.1.13)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: spatialgeometry>=1.0.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.1.0)\n",
      "Requirement already satisfied: pgraph-python in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (0.6.3)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.15.1)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (3.5.1)\n",
      "Requirement already satisfied: ansitable in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (0.11.4)\n",
      "Requirement already satisfied: swift-sim>=1.0.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.1.0)\n",
      "Requirement already satisfied: rtb-data in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.0.1)\n",
      "Requirement already satisfied: progress in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.6)\n",
      "Requirement already satisfied: typing_extensions in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (4.12.2)\n",
      "Requirement already satisfied: pre-commit in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from spatialmath-python) (4.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (2.9.0.post0)\n",
      "Requirement already satisfied: websockets in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from swift-sim>=1.0.0->roboticstoolbox-python) (13.0.1)\n",
      "Requirement already satisfied: colored in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from ansitable->roboticstoolbox-python) (2.2.4)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (2.6.5)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (6.0.2)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (20.29.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->roboticstoolbox-python) (1.17.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->spatialmath-python) (0.3.9)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->spatialmath-python) (3.16.1)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->spatialmath-python) (4.3.6)\n",
      "Requirement already satisfied: pybullet in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (3.2.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Apr  1 2025 12:02:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version = 4.1 Metal - 89.3\n",
      "Vendor = Apple\n",
      "Renderer = Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 21:18:18.901 python[40579:8433097] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-01 21:18:18.901 python[40579:8433097] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'textureUniqueId' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m texture_id \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mloadTexture(image_path)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create a visual shape with the texture\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m box_visual_shape \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateVisualShape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGEOM_BOX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalfExtents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtextureUniqueId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexture_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create a physics body and attach the visual shape\u001b[39;00m\n\u001b[1;32m     34\u001b[0m box_body \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mcreateMultiBody(\u001b[38;5;241m1\u001b[39m, box_visual_shape, p\u001b[38;5;241m.\u001b[39mcreateCollisionShape(p\u001b[38;5;241m.\u001b[39mGEOM_BOX, halfExtents\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'textureUniqueId' is an invalid keyword argument for this function"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install opencv-python roboticstoolbox-python spatialmath-python\n",
    "!pip install pybullet\n",
    "\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import roboticstoolbox as rtb\n",
    "from spatialmath import SE3\n",
    "import cv2\n",
    "\n",
    "# --- Connect to PyBullet ---\n",
    "p.connect(p.GUI)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "\n",
    "# --- Load Environment & Robot ---\n",
    "p.loadURDF(\"plane.urdf\")\n",
    "robot_id = p.loadURDF(\"franka_panda/panda.urdf\", useFixedBase=True)\n",
    "\n",
    "# Create a flat box (a thin rectangular box, e.g., 1m x 1m with a height of 0.01m)\n",
    "flat_box_half_extents = [0.5, 0.5, 0.005]  # 1x1m box with a very thin height\n",
    "flat_box_start_pos = [0, 0, 0.1]  # Position slightly above the ground\n",
    "flat_box_collision_shape = p.createCollisionShape(p.GEOM_BOX, halfExtents=flat_box_half_extents)\n",
    "\n",
    "# Load the PNG image\n",
    "image_path = \"Pickachu.png\" # Replace with the path to your image\n",
    "texture_id = p.loadTexture(image_path)\n",
    "\n",
    "# Create a visual shape with the texture\n",
    "box_visual_shape = p.createVisualShape(p.GEOM_BOX, halfExtents=[0.5, 0.5, 0.5], textureUniqueId=texture_id)\n",
    "\n",
    "# Create a physics body and attach the visual shape\n",
    "box_body = p.createMultiBody(1, box_visual_shape, p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.5, 0.5, 0.5]))\n",
    "\n",
    "# Set the initial position of the box\n",
    "p.resetBasePositionAndOrientation(box_body, [0, 0, 1], [0, 0, 0, 1])\n",
    "\n",
    "\n",
    "# --- Load Panda Model from Robotics Toolbox ---\n",
    "panda = rtb.models.Panda()  # Robotics Toolbox Panda Model\n",
    "\n",
    "# --- End-Effector Link Index ---\n",
    "ee_link = 11  # Panda's end-effector\n",
    "\n",
    "# --- Function to Get Current Joint Positions ---\n",
    "def get_current_joint_positions(robot_id):\n",
    "    return np.array([p.getJointState(robot_id, i)[0] for i in range(7)])\n",
    "\n",
    "# --- Move Robot to Desired Pose Using `ikine_LM` ---\n",
    "def move_to_pose(robot_id, panda, target_pose):\n",
    "    \"\"\"\n",
    "    Moves the Panda robot smoothly to a target end-effector pose using `ikine_LM`.\n",
    "    :param robot_id: PyBullet Panda robot ID\n",
    "    :param panda: Panda model from Robotics Toolbox\n",
    "    :param target_pose: SE3 desired pose of the end effector\n",
    "    \"\"\"\n",
    "    # Get current joint positions\n",
    "    current_joint_positions = get_current_joint_positions(robot_id)\n",
    "\n",
    "    # Solve inverse kinematics using ikine_LM\n",
    "    sol = panda.ikine_LM(target_pose, q0=current_joint_positions)\n",
    "\n",
    "    if sol.success:\n",
    "        print(\"IK Solution Found!\")\n",
    "        joint_solutions = sol.q\n",
    "        print(\"Target Joint Angles:\", joint_solutions)\n",
    "\n",
    "        # Compute number of steps based on joint movement distance\n",
    "        joint_distance = np.linalg.norm(joint_solutions - current_joint_positions)\n",
    "        num_steps = int(np.clip(joint_distance * 100, 10, 1000))\n",
    "\n",
    "        # Move smoothly to the new pose\n",
    "        for alpha in np.linspace(0, 1, num_steps):\n",
    "            intermediate_pos = (1 - alpha) * current_joint_positions + alpha * joint_solutions\n",
    "            for i in range(7):\n",
    "                p.setJointMotorControl2(robot_id, i, p.POSITION_CONTROL, targetPosition=intermediate_pos[i])\n",
    "            p.stepSimulation()\n",
    "            \n",
    "            # --- Show Camera Feed during movement ---\n",
    "            img = get_camera_image(robot_id)\n",
    "            cv2.imshow(\"RealSense Camera\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            time.sleep(1/240)\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to find IK solution!\")\n",
    "\n",
    "# --- Attach a Simulated RealSense Camera to the EE ---\n",
    "def get_camera_image(robot_id):\n",
    "    \"\"\"\n",
    "    Captures an RGB-D image from a simulated camera mounted on the Panda's EE.\n",
    "    \"\"\"\n",
    "    # --- Camera Parameters ---\n",
    "    width, height = 640, 480\n",
    "    fov = 60  # Field of view\n",
    "    aspect = width / height\n",
    "    near, far = 0.01, 2.0  # Near and far clipping planes\n",
    "\n",
    "    # --- Get End-Effector Pose ---\n",
    "    ee_state = p.getLinkState(robot_id, ee_link)\n",
    "    ee_pos, ee_orient = ee_state[0], ee_state[1]\n",
    "\n",
    "    # --- Convert Quaternion to Rotation Matrix ---\n",
    "    rot_matrix = p.getMatrixFromQuaternion(ee_orient)\n",
    "    rot_matrix = np.array(rot_matrix).reshape(3, 3)\n",
    "\n",
    "    # --- Define Camera View (RealSense facing downward) ---\n",
    "    forward_vector = np.dot(rot_matrix, [0, 0, 1])  # Z-axis in EE frame\n",
    "    up_vector = np.dot(rot_matrix, [0, -1, 0])  # Y-axis in EE frame\n",
    "    camera_pos = np.array(ee_pos) + forward_vector * 0.1  # Offset by 10 cm\n",
    "\n",
    "    # --- Compute Look-at Target ---\n",
    "    look_at = camera_pos + forward_vector\n",
    "\n",
    "    # --- Compute View & Projection Matrices ---\n",
    "    view_matrix = p.computeViewMatrix(camera_pos, look_at, up_vector)\n",
    "    proj_matrix = p.computeProjectionMatrixFOV(fov, aspect, near, far)\n",
    "\n",
    "    # --- Get Image from PyBullet ---\n",
    "    img_arr = p.getCameraImage(width, height, view_matrix, proj_matrix)\n",
    "    rgb_image = np.array(img_arr[2]).reshape(height, width, 4)[:, :, :3]\n",
    "\n",
    "    # --- Convert RGB to OpenCV format ---\n",
    "    rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return rgb_image\n",
    "\n",
    "# --- Move to an Initial Pose and Show Camera Feed During Movement ---\n",
    "start_pose = SE3(0.5, 0, 0.5) * SE3.RPY(-3.13, 0.097, 0.035)\n",
    "move_to_pose(robot_id, panda, start_pose)\n",
    "\n",
    "# --- Cleanup ---\n",
    "cv2.destroyAllWindows()\n",
    "p.disconnect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texture issues with png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: roboticstoolbox-python in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: spatialmath-python in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (1.1.13)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: spatialgeometry>=1.0.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.1.0)\n",
      "Requirement already satisfied: pgraph-python in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (0.6.3)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.15.1)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (3.5.1)\n",
      "Requirement already satisfied: ansitable in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (0.11.4)\n",
      "Requirement already satisfied: swift-sim>=1.0.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.1.0)\n",
      "Requirement already satisfied: rtb-data in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.0.1)\n",
      "Requirement already satisfied: progress in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (1.6)\n",
      "Requirement already satisfied: typing_extensions in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from roboticstoolbox-python) (4.12.2)\n",
      "Requirement already satisfied: pre-commit in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from spatialmath-python) (4.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from matplotlib->roboticstoolbox-python) (2.9.0.post0)\n",
      "Requirement already satisfied: websockets in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from swift-sim>=1.0.0->roboticstoolbox-python) (13.0.1)\n",
      "Requirement already satisfied: colored in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from ansitable->roboticstoolbox-python) (2.2.4)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (2.6.5)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (6.0.2)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from pre-commit->spatialmath-python) (20.29.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->roboticstoolbox-python) (1.17.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->spatialmath-python) (0.3.9)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->spatialmath-python) (3.16.1)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->spatialmath-python) (4.3.6)\n",
      "Requirement already satisfied: pybullet in /opt/miniconda3/envs/BME1530/lib/python3.10/site-packages (3.2.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Apr  1 2025 12:02:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version = 4.1 Metal - 89.3\n",
      "Vendor = Apple\n",
      "Renderer = Apple M1 Pro\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 21:42:39.428 python[41035:8453668] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-01 21:42:39.428 python[41035:8453668] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# --- Move to an Initial Pose and Show Camera Feed During Movement ---\u001b[39;00m\n\u001b[1;32m    113\u001b[0m start_pose \u001b[38;5;241m=\u001b[39m SE3(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m*\u001b[39m SE3\u001b[38;5;241m.\u001b[39mRPY(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3.13\u001b[39m, \u001b[38;5;241m0.097\u001b[39m, \u001b[38;5;241m0.035\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m \u001b[43mmove_to_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrobot_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# --- Cleanup ---\u001b[39;00m\n\u001b[1;32m    117\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "Cell \u001b[0;32mIn[1], line 78\u001b[0m, in \u001b[0;36mmove_to_pose\u001b[0;34m(robot_id, panda, target_pose)\u001b[0m\n\u001b[1;32m     75\u001b[0m     p\u001b[38;5;241m.\u001b[39msetJointMotorControl2(robot_id, i, p\u001b[38;5;241m.\u001b[39mPOSITION_CONTROL, targetPosition\u001b[38;5;241m=\u001b[39mintermediate_pos[i])\n\u001b[1;32m     76\u001b[0m p\u001b[38;5;241m.\u001b[39mstepSimulation()\n\u001b[0;32m---> 78\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mget_camera_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrobot_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRealSense Camera\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[0;32mIn[1], line 106\u001b[0m, in \u001b[0;36mget_camera_image\u001b[0;34m(robot_id)\u001b[0m\n\u001b[1;32m    103\u001b[0m view_matrix \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mcomputeViewMatrix(camera_pos, look_at, up_vector)\n\u001b[1;32m    104\u001b[0m proj_matrix \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mcomputeProjectionMatrixFOV(fov, aspect, near, far)\n\u001b[0;32m--> 106\u001b[0m img_arr \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetCameraImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproj_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m rgb_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img_arr[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(height, width, \u001b[38;5;241m4\u001b[39m)[:, :, :\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m    108\u001b[0m rgb_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(rgb_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install opencv-python roboticstoolbox-python spatialmath-python\n",
    "!pip install pybullet\n",
    "\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import roboticstoolbox as rtb\n",
    "from spatialmath import SE3\n",
    "\n",
    "# --- Connect to PyBullet ---\n",
    "p.connect(p.GUI)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "\n",
    "# --- Load Environment & Robot ---\n",
    "p.loadURDF(\"plane.urdf\")  # Load the ground\n",
    "robot_id = p.loadURDF(\"franka_panda/panda.urdf\", useFixedBase=True)\n",
    "\n",
    "# --- Load Panda Model from Robotics Toolbox ---\n",
    "panda = rtb.models.Panda()\n",
    "\n",
    "# --- End-Effector Link Index ---\n",
    "ee_link = 11\n",
    "\n",
    "# --- Create a Small Box for the Image Instead of a Plane ---\n",
    "image_size = 0.3  # Adjust this for desired image area\n",
    "image_position = [0.5, 0, 0.01]  # Slightly above the ground\n",
    "\n",
    "# Create a small box instead of using a plane\n",
    "visual_shape_id = p.createVisualShape(\n",
    "    shapeType=p.GEOM_BOX,\n",
    "    halfExtents=[image_size / 2, image_size / 2, 0.15],  # Thin box\n",
    ")\n",
    "\n",
    "collision_shape_id = p.createCollisionShape(\n",
    "    shapeType=p.GEOM_BOX,\n",
    "    halfExtents=[image_size / 2, image_size / 2, 0.001],  # Same as visual\n",
    ")\n",
    "\n",
    "image_plane_id = p.createMultiBody(\n",
    "    baseMass=0,  # Static object\n",
    "    baseCollisionShapeIndex=collision_shape_id,\n",
    "    baseVisualShapeIndex=visual_shape_id,\n",
    "    basePosition=image_position\n",
    ")\n",
    "\n",
    "\n",
    "# --- Load and Apply a Texture to the Small Box ---\n",
    "image_path = \"/Users/ericliang/Downloads/2025-03-31-160142.png\"  # Replace with your image path\n",
    "texture_id = p.loadTexture(image_path)\n",
    "p.changeVisualShape(image_plane_id, -1, textureUniqueId=texture_id)\n",
    "\n",
    "\n",
    "\n",
    "# --- Function to Get Current Joint Positions ---\n",
    "def get_current_joint_positions(robot_id):\n",
    "    return np.array([p.getJointState(robot_id, i)[0] for i in range(7)])\n",
    "\n",
    "# --- Move Robot to Desired Pose Using `ikine_LM` ---\n",
    "def move_to_pose(robot_id, panda, target_pose):\n",
    "    \"\"\"\n",
    "    Moves the Panda robot smoothly to a target end-effector pose using `ikine_LM`.\n",
    "    \"\"\"\n",
    "    current_joint_positions = get_current_joint_positions(robot_id)\n",
    "    sol = panda.ikine_LM(target_pose, q0=current_joint_positions)\n",
    "\n",
    "    if sol.success:\n",
    "        joint_solutions = sol.q\n",
    "        num_steps = int(np.clip(np.linalg.norm(joint_solutions - current_joint_positions) * 100, 10, 1000))\n",
    "\n",
    "        for alpha in np.linspace(0, 1, num_steps):\n",
    "            intermediate_pos = (1 - alpha) * current_joint_positions + alpha * joint_solutions\n",
    "            for i in range(7):\n",
    "                p.setJointMotorControl2(robot_id, i, p.POSITION_CONTROL, targetPosition=intermediate_pos[i])\n",
    "            p.stepSimulation()\n",
    "\n",
    "            img = get_camera_image(robot_id)\n",
    "            cv2.imshow(\"RealSense Camera\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            time.sleep(1/240)\n",
    "    else:\n",
    "        print(\"Failed to find IK solution!\")\n",
    "\n",
    "# --- Attach a Simulated RealSense Camera to the EE ---\n",
    "def get_camera_image(robot_id):\n",
    "    width, height = 640, 480\n",
    "    fov = 60\n",
    "    aspect = width / height\n",
    "    near, far = 0.01, 2.0\n",
    "\n",
    "    ee_state = p.getLinkState(robot_id, ee_link)\n",
    "    ee_pos, ee_orient = ee_state[0], ee_state[1]\n",
    "\n",
    "    rot_matrix = np.array(p.getMatrixFromQuaternion(ee_orient)).reshape(3, 3)\n",
    "    forward_vector = np.dot(rot_matrix, [0, 0, 1])\n",
    "    up_vector = np.dot(rot_matrix, [0, -1, 0])\n",
    "    camera_pos = np.array(ee_pos) + forward_vector * 0.1\n",
    "    look_at = camera_pos + forward_vector\n",
    "\n",
    "    view_matrix = p.computeViewMatrix(camera_pos, look_at, up_vector)\n",
    "    proj_matrix = p.computeProjectionMatrixFOV(fov, aspect, near, far)\n",
    "\n",
    "    img_arr = p.getCameraImage(width, height, view_matrix, proj_matrix)\n",
    "    rgb_image = np.array(img_arr[2]).reshape(height, width, 4)[:, :, :3]\n",
    "    rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return rgb_image\n",
    "\n",
    "# --- Move to an Initial Pose and Show Camera Feed During Movement ---\n",
    "start_pose = SE3(0.5, 0, 0.5) * SE3.RPY(-3.13, 0.097, 0.035)\n",
    "move_to_pose(robot_id, panda, start_pose)\n",
    "\n",
    "# --- Cleanup ---\n",
    "cv2.destroyAllWindows()\n",
    "p.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BME1530",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
